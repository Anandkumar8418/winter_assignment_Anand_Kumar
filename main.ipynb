import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import random
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras import layers, Model

# Part 1: Data Generation
class MerchantProfileGenerator:
    def __init__(self):
        self.business_types = ['Retail', 'Restaurant', 'E-commerce', 'Services', 'Wholesale']
        self.gst_status = ['Active', 'Inactive', 'Pending']
        
    def generate_merchants(self, num_merchants):
        merchants = []
        for i in range(num_merchants):
            merchant = {
                'merchant_id': f'M{str(i).zfill(6)}',
                'name': f'Merchant_{i}',
                'business_type': random.choice(self.business_types),
                'registration_date': (datetime.now() - timedelta(days=random.randint(1, 1000))).date(),
                'gst_status': random.choice(self.gst_status),
                'is_fraudulent': random.random() < 0.2  # 20% fraudulent merchants
            }
            merchants.append(merchant)
        return pd.DataFrame(merchants)

class TransactionGenerator:
    def __init__(self):
        self.current_date = datetime.now()
        
    def generate_normal_transactions(self, merchant_id, num_days):
        transactions = []
        for _ in range(random.randint(50, 200)):  # Random number of transactions
            transaction_date = self.current_date - timedelta(days=random.randint(0, num_days))
            amount = random.normalvariate(1000, 300)  # Normal distribution
            customer_id = f'C{random.randint(1, 1000)}'
            
            transactions.append({
                'merchant_id': merchant_id,
                'transaction_date': transaction_date,
                'amount': max(10, amount),  # Ensure positive amount
                'customer_id': customer_id
            })
        return transactions
    
    def generate_fraudulent_transactions(self, merchant_id, num_days):
        transactions = []
        fraud_type = random.choice(['late_night', 'high_velocity', 'customer_concentration'])
        
        if fraud_type == 'late_night':
            # Generate late night transactions
            for _ in range(random.randint(20, 50)):
                transaction_date = self.current_date - timedelta(days=random.randint(0, num_days))
                transaction_date = transaction_date.replace(
                    hour=random.randint(23, 24) if random.random() < 0.5 else random.randint(0, 4),
                    minute=random.randint(0, 59)
                )
                amount = random.normalvariate(2000, 500)
                customer_id = f'C{random.randint(1, 1000)}'
                transactions.append({
                    'merchant_id': merchant_id,
                    'transaction_date': transaction_date,
                    'amount': max(10, amount),
                    'customer_id': customer_id
                })
                
        elif fraud_type == 'high_velocity':
            # Generate high velocity spikes
            spike_day = self.current_date - timedelta(days=random.randint(0, num_days))
            for _ in range(random.randint(100, 200)):
                transaction_date = spike_day + timedelta(hours=random.randint(0, 24))
                amount = random.normalvariate(1500, 400)
                customer_id = f'C{random.randint(1, 1000)}'
                transactions.append({
                    'merchant_id': merchant_id,
                    'transaction_date': transaction_date,
                    'amount': max(10, amount),
                    'customer_id': customer_id
                })
                
        else:  # customer_concentration
            # Generate transactions with high customer concentration
            main_customer = f'C{random.randint(1, 100)}'
            for _ in range(random.randint(50, 150)):
                transaction_date = self.current_date - timedelta(days=random.randint(0, num_days))
                amount = random.normalvariate(1200, 300)
                customer_id = main_customer if random.random() < 0.8 else f'C{random.randint(1, 1000)}'
                transactions.append({
                    'merchant_id': merchant_id,
                    'transaction_date': transaction_date,
                    'amount': max(10, amount),
                    'customer_id': customer_id
                })
                
        return transactions

# Part 2: Feature Engineering
class FeatureEngineer:
    def __init__(self):
        self.scaler = StandardScaler()
        
    def calculate_merchant_features(self, transactions_df):
        features = []
        
        for merchant_id in transactions_df['merchant_id'].unique():
            merchant_txns = transactions_df[transactions_df['merchant_id'] == merchant_id]
            
            # Transaction velocity metrics
            daily_txn_counts = merchant_txns.groupby(
                merchant_txns['transaction_date'].dt.date
            ).size().describe()
            
            # Time-based patterns
            hour_distribution = merchant_txns['transaction_date'].dt.hour.value_counts(normalize=True)
            night_txn_ratio = hour_distribution[
                [h for h in range(24) if h >= 22 or h <= 4]
            ].sum() if len(hour_distribution) > 0 else 0
            
            # Amount distributions
            amount_stats = merchant_txns['amount'].describe()
            
            # Customer concentration
            customer_concentration = (
                merchant_txns.groupby('customer_id').size().max() / 
                len(merchant_txns)
            )
            
            features.append({
                'merchant_id': merchant_id,
                'avg_daily_txns': daily_txn_counts['mean'],
                'max_daily_txns': daily_txn_counts['max'],
                'std_daily_txns': daily_txn_counts['std'],
                'night_txn_ratio': night_txn_ratio,
                'avg_amount': amount_stats['mean'],
                'std_amount': amount_stats['std'],
                'customer_concentration': customer_concentration
            })
            
        features_df = pd.DataFrame(features)
        return features_df
    
    def normalize_features(self, features_df):
        feature_columns = features_df.columns.difference(['merchant_id'])
        normalized_features = self.scaler.fit_transform(features_df[feature_columns])
        return normalized_features

# Part 3: Autoencoder Model
class FraudDetectionAutoencoder:
    def __init__(self, input_dim):
        self.input_dim = input_dim
        self.model = self._build_model()
        self.threshold = None
        
    def _build_model(self):
        input_layer = layers.Input(shape=(self.input_dim,))
        
        # Encoder
        encoded = layers.Dense(32, activation='relu')(input_layer)
        encoded = layers.Dense(16, activation='relu')(encoded)
        encoded = layers.Dense(8, activation='relu')(encoded)
        
        # Decoder
        decoded = layers.Dense(16, activation='relu')(encoded)
        decoded = layers.Dense(32, activation='relu')(decoded)
        decoded = layers.Dense(self.input_dim, activation='sigmoid')(decoded)
        
        autoencoder = Model(input_layer, decoded)
        autoencoder.compile(optimizer='adam', loss='mse')
        
        return autoencoder
    
    def train(self, X_train, epochs=50, batch_size=32):
        self.model.fit(
            X_train, X_train,
            epochs=epochs,
            batch_size=batch_size,
            shuffle=True,
            validation_split=0.1
        )
        
        # Calculate reconstruction error threshold
        reconstructed = self.model.predict(X_train)
        mse = np.mean(np.power(X_train - reconstructed, 2), axis=1)
        self.threshold = np.percentile(mse, 95)  # 95th percentile as threshold
        
    def get_anomaly_scores(self, X):
        reconstructed = self.model.predict(X)
        mse = np.mean(np.power(X - reconstructed, 2), axis=1)
        return mse / self.threshold  # Normalized anomaly scores

# Part 4: Fraud Pattern Detection
class FraudPatternDetector:
    def __init__(self):
        self.velocity_threshold = 3.0  # Standard deviations above mean
        self.night_ratio_threshold = 0.3
        self.concentration_threshold = 0.5
        
    def detect_patterns(self, features_df, anomaly_scores):
        patterns = []
        
        for idx, row in features_df.iterrows():
            merchant_patterns = []
            
            # High velocity detection
            if (row['max_daily_txns'] - row['avg_daily_txns']) / row['std_daily_txns'] > self.velocity_threshold:
                merchant_patterns.append('high_velocity')
                
            # Odd-hour pattern detection
            if row['night_txn_ratio'] > self.night_ratio_threshold:
                merchant_patterns.append('odd_hours')
                
            # Customer concentration analysis
            if row['customer_concentration'] > self.concentration_threshold:
                merchant_patterns.append('customer_concentration')
                
            patterns.append({
                'merchant_id': row['merchant_id'],
                'anomaly_score': anomaly_scores[idx],
                'detected_patterns': merchant_patterns,
                'is_suspicious': anomaly_scores[idx] > 1.0 or len(merchant_patterns) > 0
            })
            
        return pd.DataFrame(patterns)

# Example usage
def main():
    # Generate sample data
    merchant_generator = MerchantProfileGenerator()
    transaction_generator = TransactionGenerator()
    
    # Generate 100 merchants
    merchants_df = merchant_generator.generate_merchants(100)
    
    # Generate transactions
    all_transactions = []
    for _, merchant in merchants_df.iterrows():
        if merchant['is_fraudulent']:
            transactions = transaction_generator.generate_fraudulent_transactions(
                merchant['merchant_id'], 30
            )
        else:
            transactions = transaction_generator.generate_normal_transactions(
                merchant['merchant_id'], 30
            )
        all_transactions.extend(transactions)
    
    transactions_df = pd.DataFrame(all_transactions)
    
    # Feature engineering
    feature_engineer = FeatureEngineer()
    features_df = feature_engineer.calculate_merchant_features(transactions_df)
    normalized_features = feature_engineer.normalize_features(features_df)
    
    # Train autoencoder
    autoencoder = FraudDetectionAutoencoder(normalized_features.shape[1])
    autoencoder.train(normalized_features)
    
    # Get anomaly scores
    anomaly_scores = autoencoder.get_anomaly_scores(normalized_features)
    
    # Detect fraud patterns
    pattern_detector = FraudPatternDetector()
    results = pattern_detector.detect_patterns(features_df, anomaly_scores)
    
    # Print suspicious merchants
    suspicious_merchants = results[results['is_suspicious']]
    print("\nSuspicious Merchants:")
    print(suspicious_merchants[['merchant_id', 'anomaly_score', 'detected_patterns']])

if __name__ == "__main__":
    main()